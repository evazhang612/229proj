{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from datetime import datetime \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.linear_model import LinearRegression\n",
    "#parse data \n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from matplotlib import pyplot\n",
    "\n",
    "#label encoding on categorical data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.]\n",
      " [2.]\n",
      " [2.]\n",
      " ...\n",
      " [3.]\n",
      " [3.]\n",
      " [3.]]\n",
      "(20577, 71)\n",
      "(20577, 1)\n"
     ]
    }
   ],
   "source": [
    "import sklearn.preprocessing \n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#preprocessing here\n",
    "#sort by date \n",
    "df = pd.read_csv('FAMA_49CRSP.csv', dtype={'public_date' : str})\n",
    "df = df.sort_values(by = 'public_date', ascending = True)\n",
    "df = df.dropna()\n",
    "\n",
    "#encode integer categories into numbers \n",
    "label_encoder = LabelEncoder()\n",
    "integer_encoded = label_encoder.fit_transform(df.FFI49_desc)\n",
    "df.FFI49_desc = integer_encoded\n",
    "\n",
    "#df = df.dropna()\n",
    "\n",
    "ew_indret = df['indret_ew']\n",
    "\n",
    "df = df.drop(labels=['indret_ew', 'indret_vw'], axis=1)\n",
    "\n",
    "\n",
    "#make a new output (bucket by percentage?)\n",
    "enc = KBinsDiscretizer(n_bins=8, encode='ordinal',strategy='uniform')\n",
    "labels_binned = enc.fit_transform(np.asarray(ew_indret).reshape(-1, 1))\n",
    "print(labels_binned)\n",
    "print(df.shape)\n",
    "print(labels_binned.shape)\n",
    "# labels_binned = labels_binned[:-2]\n",
    "\n",
    "#1 Split-Timer series data, 0.64 Train, 0.16 dev, 0.2 Test\n",
    "#x_train, x_test, y_train, y_test = train_test_split(df, labels_binned, test_size = 0.2, shuffle = False)\n",
    "x_train, x_test, y_train, y_test = train_test_split(df, labels_binned, test_size = 0.2, shuffle = False)\n",
    "x_train, x_dev, y_train, y_dev = train_test_split(x_train, y_train, test_size = 0.2, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_dates(x_train, x_dev, x_test):\n",
    "    train_dates = [datetime(year=int(x[0:4]), month=int(x[4:6]), day=int(x[6:8])) for x in x_train['public_date']] \n",
    "    dev_dates = [datetime(year=int(x[0:4]), month=int(x[4:6]), day=int(x[6:8])) for x in x_dev['public_date']]\n",
    "    test_dates = [datetime(year=int(x[0:4]), month=int(x[4:6]), day=int(x[6:8])) for x in x_test['public_date']]\n",
    "    \n",
    "    x_train = x_train.drop('public_date', axis=1)\n",
    "    x_dev = x_dev.drop('public_date', axis=1)\n",
    "    x_test = x_test.drop('public_date', axis=1)\n",
    "    \n",
    "    return train_dates, dev_dates, test_dates, x_train, x_dev, x_test\n",
    "\n",
    "train_dates, dev_dates, test_dates, x_train, x_dev, x_test = get_dates(x_train, x_dev, x_test)\n",
    "\n",
    "fig1 = pyplot.figure(1, figsize = (6,6))\n",
    "pyplot.plot(train_dates, y_train, color = 'green', label = 'industry_ew_train')\n",
    "pyplot.plot(dev_dates, y_dev, color = 'yellow', label = 'industry_ew_dev')\n",
    "pyplot.plot(test_dates, y_test, color = 'red', label = 'industry_ew_test')\n",
    "pyplot.xlabel('Date')\n",
    "pyplot.ylabel('Industry Return (Equally Weighted)')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13168\n",
      "3293\n",
      "4116\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "print(x_train.shape[0])\n",
    "print(x_dev.shape[0])\n",
    "print(x_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "13168/13168 [==============================] - 2s 148us/step - loss: 42.9989 - acc: 0.0000e+00\n",
      "Epoch 2/100\n",
      "13168/13168 [==============================] - 0s 33us/step - loss: 41.9596 - acc: 0.0000e+00\n",
      "Epoch 3/100\n",
      "13168/13168 [==============================] - 0s 34us/step - loss: 41.7142 - acc: 0.0000e+00\n",
      "Epoch 4/100\n",
      "13168/13168 [==============================] - 0s 33us/step - loss: 41.6884 - acc: 0.0000e+00\n",
      "Epoch 5/100\n",
      "13168/13168 [==============================] - 0s 33us/step - loss: 41.6874 - acc: 0.0000e+00\n",
      "Epoch 6/100\n",
      "13168/13168 [==============================] - 0s 33us/step - loss: 41.6874 - acc: 0.0000e+00\n",
      "Epoch 7/100\n",
      "13168/13168 [==============================] - 0s 33us/step - loss: 41.6874 - acc: 0.0000e+00\n",
      "Epoch 8/100\n",
      "13168/13168 [==============================] - 0s 31us/step - loss: 41.6874 - acc: 0.0228\n",
      "Epoch 9/100\n",
      "13168/13168 [==============================] - 0s 32us/step - loss: 41.6874 - acc: 0.0683\n",
      "Epoch 10/100\n",
      "13168/13168 [==============================] - 0s 31us/step - loss: 41.6874 - acc: 0.0228\n",
      "Epoch 11/100\n",
      "13168/13168 [==============================] - 0s 31us/step - loss: 41.6874 - acc: 0.2734\n",
      "Epoch 12/100\n",
      "13168/13168 [==============================] - 0s 31us/step - loss: 41.6874 - acc: 0.2962\n",
      "Epoch 13/100\n",
      "13168/13168 [==============================] - 0s 32us/step - loss: 41.6874 - acc: 0.2962\n",
      "Epoch 14/100\n",
      "13168/13168 [==============================] - 0s 31us/step - loss: 41.6874 - acc: 0.2710\n",
      "Epoch 15/100\n",
      "13168/13168 [==============================] - 0s 31us/step - loss: 41.6874 - acc: 0.3873\n",
      "Epoch 16/100\n",
      "13168/13168 [==============================] - 0s 34us/step - loss: 41.6874 - acc: 0.5468\n",
      "Epoch 17/100\n",
      "13168/13168 [==============================] - 0s 33us/step - loss: 41.6874 - acc: 0.5696\n",
      "Epoch 18/100\n",
      "13168/13168 [==============================] - 0s 30us/step - loss: 41.6874 - acc: 0.5443\n",
      "Epoch 19/100\n",
      "13168/13168 [==============================] - 0s 30us/step - loss: 41.6874 - acc: 0.4532\n",
      "Epoch 20/100\n",
      "13168/13168 [==============================] - 0s 31us/step - loss: 41.6874 - acc: 0.5240\n",
      "Epoch 21/100\n",
      "13168/13168 [==============================] - 0s 33us/step - loss: 41.6874 - acc: 0.5240\n",
      "Epoch 22/100\n",
      "13168/13168 [==============================] - 0s 30us/step - loss: 41.6874 - acc: 0.5216\n",
      "Epoch 23/100\n",
      "13168/13168 [==============================] - 0s 31us/step - loss: 41.6874 - acc: 0.9317\n",
      "Epoch 24/100\n",
      "13168/13168 [==============================] - 0s 32us/step - loss: 41.6874 - acc: 1.0000\n",
      "Epoch 25/100\n",
      "13168/13168 [==============================] - 0s 35us/step - loss: 41.6874 - acc: 1.0000\n",
      "Epoch 26/100\n",
      "13168/13168 [==============================] - 0s 35us/step - loss: 41.6874 - acc: 1.0000\n",
      "Epoch 27/100\n",
      "13168/13168 [==============================] - 0s 34us/step - loss: 41.6874 - acc: 1.0000\n",
      "Epoch 28/100\n",
      "13168/13168 [==============================] - 0s 37us/step - loss: 41.6874 - acc: 1.0000\n",
      "Epoch 29/100\n",
      "13168/13168 [==============================] - 0s 32us/step - loss: 41.6874 - acc: 1.0000\n",
      "Epoch 30/100\n",
      "13168/13168 [==============================] - 0s 32us/step - loss: 41.6874 - acc: 1.0000\n",
      "Epoch 31/100\n",
      "13168/13168 [==============================] - 0s 34us/step - loss: 41.6874 - acc: 1.0000\n",
      "Epoch 32/100\n",
      "13168/13168 [==============================] - 0s 33us/step - loss: 41.6874 - acc: 1.0000\n",
      "Epoch 33/100\n",
      "13168/13168 [==============================] - 0s 33us/step - loss: 41.6874 - acc: 1.0000\n",
      "Epoch 34/100\n",
      "13168/13168 [==============================] - 0s 32us/step - loss: 41.6874 - acc: 1.0000\n",
      "Epoch 35/100\n",
      "13168/13168 [==============================] - 0s 31us/step - loss: 41.6874 - acc: 1.0000\n",
      "Epoch 36/100\n",
      "13168/13168 [==============================] - 0s 32us/step - loss: 41.6874 - acc: 1.0000\n",
      "Epoch 37/100\n",
      "13168/13168 [==============================] - 0s 33us/step - loss: 41.6874 - acc: 1.0000\n",
      "Epoch 38/100\n",
      "13168/13168 [==============================] - 0s 31us/step - loss: 41.6874 - acc: 1.0000\n",
      "Epoch 39/100\n",
      "13168/13168 [==============================] - 0s 31us/step - loss: 41.6874 - acc: 1.0000\n",
      "Epoch 40/100\n",
      "13168/13168 [==============================] - 0s 31us/step - loss: 41.6874 - acc: 1.0000\n",
      "Epoch 41/100\n",
      "13168/13168 [==============================] - 0s 30us/step - loss: 41.6874 - acc: 1.0000\n",
      "Epoch 42/100\n",
      "13168/13168 [==============================] - 0s 30us/step - loss: 41.6874 - acc: 1.0000\n",
      "Epoch 43/100\n",
      "13168/13168 [==============================] - 0s 31us/step - loss: 41.6874 - acc: 1.0000\n",
      "Epoch 44/100\n",
      "13168/13168 [==============================] - 0s 31us/step - loss: 41.6874 - acc: 1.0000\n",
      "Epoch 45/100\n",
      "13168/13168 [==============================] - 0s 35us/step - loss: 41.6874 - acc: 1.0000\n",
      "Epoch 46/100\n",
      "13168/13168 [==============================] - 0s 31us/step - loss: 41.6874 - acc: 1.0000\n",
      "Epoch 47/100\n",
      "13168/13168 [==============================] - 0s 31us/step - loss: 41.6874 - acc: 1.0000\n",
      "Epoch 48/100\n",
      "13168/13168 [==============================] - 0s 31us/step - loss: 41.6874 - acc: 1.0000\n",
      "Epoch 49/100\n",
      "13168/13168 [==============================] - 0s 31us/step - loss: 41.6874 - acc: 1.0000\n",
      "Epoch 50/100\n",
      "13168/13168 [==============================] - 0s 31us/step - loss: 41.6874 - acc: 1.0000\n",
      "Epoch 51/100\n",
      "13168/13168 [==============================] - 0s 30us/step - loss: 41.6874 - acc: 1.0000\n",
      "Epoch 52/100\n",
      "13168/13168 [==============================] - 0s 30us/step - loss: 41.6874 - acc: 1.0000\n",
      "Epoch 53/100\n",
      "13168/13168 [==============================] - 0s 30us/step - loss: 41.6874 - acc: 1.0000\n",
      "Epoch 54/100\n",
      "13168/13168 [==============================] - 0s 31us/step - loss: 41.6874 - acc: 1.0000\n",
      "Epoch 55/100\n",
      "13168/13168 [==============================] - 0s 31us/step - loss: 41.6874 - acc: 1.0000\n",
      "Epoch 56/100\n",
      "13168/13168 [==============================] - 0s 32us/step - loss: 41.6874 - acc: 1.0000\n",
      "Epoch 57/100\n",
      "13168/13168 [==============================] - 0s 32us/step - loss: 41.6874 - acc: 1.0000\n",
      "Epoch 58/100\n",
      "13168/13168 [==============================] - 0s 31us/step - loss: 41.6874 - acc: 1.0000\n",
      "Epoch 59/100\n",
      "13168/13168 [==============================] - 0s 31us/step - loss: 41.6874 - acc: 1.0000\n",
      "Epoch 60/100\n",
      "13168/13168 [==============================] - 0s 30us/step - loss: 41.6874 - acc: 1.0000\n",
      "Epoch 61/100\n",
      "13168/13168 [==============================] - 0s 31us/step - loss: 41.6874 - acc: 1.0000\n",
      "Epoch 62/100\n",
      "13168/13168 [==============================] - 0s 31us/step - loss: 41.6874 - acc: 1.0000\n",
      "Epoch 63/100\n",
      "13168/13168 [==============================] - 0s 31us/step - loss: 41.6874 - acc: 1.0000\n",
      "Epoch 64/100\n",
      "13168/13168 [==============================] - 0s 31us/step - loss: 41.6874 - acc: 1.0000\n",
      "Epoch 65/100\n",
      "13168/13168 [==============================] - 0s 31us/step - loss: 41.6874 - acc: 1.0000\n",
      "Epoch 66/100\n",
      "13168/13168 [==============================] - 0s 31us/step - loss: 41.6874 - acc: 1.0000\n",
      "Epoch 67/100\n",
      "13168/13168 [==============================] - 0s 30us/step - loss: 41.6874 - acc: 1.0000\n",
      "Epoch 68/100\n",
      "13168/13168 [==============================] - 0s 32us/step - loss: 41.6874 - acc: 1.0000\n",
      "Epoch 69/100\n",
      "13168/13168 [==============================] - 0s 33us/step - loss: 41.6874 - acc: 1.0000\n",
      "Epoch 70/100\n",
      "13168/13168 [==============================] - 0s 29us/step - loss: 41.6874 - acc: 1.0000\n",
      "Epoch 71/100\n",
      "13168/13168 [==============================] - 0s 29us/step - loss: 41.6874 - acc: 1.0000\n",
      "Epoch 72/100\n",
      "13168/13168 [==============================] - 0s 29us/step - loss: 41.6874 - acc: 1.0000\n",
      "Epoch 73/100\n",
      "13168/13168 [==============================] - 0s 29us/step - loss: 41.6874 - acc: 1.0000\n",
      "Epoch 74/100\n",
      "13168/13168 [==============================] - 0s 29us/step - loss: 41.6874 - acc: 1.0000\n",
      "Epoch 75/100\n",
      "13168/13168 [==============================] - 0s 30us/step - loss: 41.6874 - acc: 1.0000\n",
      "Epoch 76/100\n",
      "13168/13168 [==============================] - 0s 30us/step - loss: 41.6874 - acc: 1.0000\n",
      "Epoch 77/100\n",
      "13168/13168 [==============================] - 0s 29us/step - loss: 41.6874 - acc: 1.0000\n",
      "Epoch 78/100\n",
      "13168/13168 [==============================] - 0s 30us/step - loss: 41.6874 - acc: 1.0000\n",
      "Epoch 79/100\n",
      "13168/13168 [==============================] - 0s 29us/step - loss: 41.6874 - acc: 1.0000\n",
      "Epoch 80/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13168/13168 [==============================] - 0s 30us/step - loss: 41.6874 - acc: 1.0000\n",
      "Epoch 81/100\n",
      "13168/13168 [==============================] - 0s 30us/step - loss: 41.6874 - acc: 1.0000\n",
      "Epoch 82/100\n",
      "13168/13168 [==============================] - 0s 32us/step - loss: 41.6874 - acc: 1.0000\n",
      "Epoch 83/100\n",
      "13168/13168 [==============================] - 0s 32us/step - loss: 41.6874 - acc: 1.0000\n",
      "Epoch 84/100\n",
      "13168/13168 [==============================] - 0s 32us/step - loss: 41.6874 - acc: 1.0000\n",
      "Epoch 85/100\n",
      "13168/13168 [==============================] - 0s 35us/step - loss: 41.6874 - acc: 1.0000\n",
      "Epoch 86/100\n",
      "13168/13168 [==============================] - 1s 41us/step - loss: 41.6874 - acc: 1.0000\n",
      "Epoch 87/100\n",
      "13168/13168 [==============================] - 1s 40us/step - loss: 41.6874 - acc: 1.0000\n",
      "Epoch 88/100\n",
      "13168/13168 [==============================] - 0s 30us/step - loss: 41.6874 - acc: 1.0000\n",
      "Epoch 89/100\n",
      "13168/13168 [==============================] - 0s 31us/step - loss: 41.6874 - acc: 1.0000\n",
      "Epoch 90/100\n",
      "13168/13168 [==============================] - 0s 37us/step - loss: 41.6874 - acc: 1.0000\n",
      "Epoch 91/100\n",
      "13168/13168 [==============================] - 1s 40us/step - loss: 41.6874 - acc: 1.0000\n",
      "Epoch 92/100\n",
      "13168/13168 [==============================] - 0s 30us/step - loss: 41.6874 - acc: 1.0000\n",
      "Epoch 93/100\n",
      "13168/13168 [==============================] - 0s 30us/step - loss: 41.6874 - acc: 1.0000\n",
      "Epoch 94/100\n",
      "13168/13168 [==============================] - 0s 29us/step - loss: 41.6874 - acc: 1.0000\n",
      "Epoch 95/100\n",
      "13168/13168 [==============================] - 0s 30us/step - loss: 41.6874 - acc: 1.0000\n",
      "Epoch 96/100\n",
      "13168/13168 [==============================] - 0s 30us/step - loss: 41.6874 - acc: 1.0000\n",
      "Epoch 97/100\n",
      "13168/13168 [==============================] - 0s 30us/step - loss: 41.6874 - acc: 1.0000\n",
      "Epoch 98/100\n",
      "13168/13168 [==============================] - 0s 30us/step - loss: 41.6874 - acc: 1.0000\n",
      "Epoch 99/100\n",
      "13168/13168 [==============================] - 0s 32us/step - loss: 41.6874 - acc: 1.0000\n",
      "Epoch 100/100\n",
      "13168/13168 [==============================] - 0s 36us/step - loss: 41.6874 - acc: 1.0000\n",
      "3293/3293 [==============================] - 1s 259us/step\n",
      "41.34887072774295 0.9996963253761185\n",
      "XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
      "4116/4116 [==============================] - 0s 32us/step\n",
      "\n",
      "loss: 4114.02%\n",
      "\n",
      "acc: 100.00%\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(76, activation=tf.nn.sigmoid),\n",
    "    keras.layers.Dense(60, activation=tf.nn.softmax),\n",
    "    keras.layers.Dense(40, activation=keras.activations.linear),\n",
    "    keras.layers.Dense(10, activation=tf.nn.sigmoid),\n",
    "    keras.layers.Dense(8, activation=tf.nn.softmax)\n",
    "])\n",
    "\n",
    "model.compile(optimizer=tf.train.AdamOptimizer(), \n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(np.asarray(x_train), np.asarray(y_train), epochs=100, batch_size=300)\n",
    "test_loss, test_accuracy = model.evaluate(np.asarray(x_dev), y_dev)\n",
    "\n",
    "print(test_loss, test_accuracy)\n",
    "\n",
    "print('XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX')\n",
    "\n",
    "test_predictions = model.predict(x_test) \n",
    "scores = model.evaluate(np.asarray(x_test), y_test)\n",
    "for i in range(len(scores)):\n",
    "    print(\"\\n%s: %.2f%%\" % (model.metrics_names[i], scores[i]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "13167/13167 [==============================] - 1s 84us/step - loss: 1.3799 - acc: 8.3542e-04\n",
      "Epoch 2/100\n",
      "13167/13167 [==============================] - 1s 54us/step - loss: 0.4698 - acc: 8.3542e-04\n",
      "Epoch 3/100\n",
      "13167/13167 [==============================] - 1s 55us/step - loss: 0.1921 - acc: 8.3542e-04\n",
      "Epoch 4/100\n",
      "13167/13167 [==============================] - 1s 60us/step - loss: 0.0972 - acc: 8.3542e-04\n",
      "Epoch 5/100\n",
      "13167/13167 [==============================] - 1s 61us/step - loss: 0.0555 - acc: 8.3542e-04\n",
      "Epoch 6/100\n",
      "13167/13167 [==============================] - 1s 58us/step - loss: 0.0344 - acc: 8.3542e-04\n",
      "Epoch 7/100\n",
      "13167/13167 [==============================] - 1s 57us/step - loss: 0.0229 - acc: 8.3542e-04\n",
      "Epoch 8/100\n",
      "13167/13167 [==============================] - 1s 59us/step - loss: 0.0160 - acc: 8.3542e-04\n",
      "Epoch 9/100\n",
      "13167/13167 [==============================] - 1s 57us/step - loss: 0.0117 - acc: 8.3542e-04\n",
      "Epoch 10/100\n",
      "13167/13167 [==============================] - 1s 57us/step - loss: 0.0087 - acc: 8.3542e-04\n",
      "Epoch 11/100\n",
      "13167/13167 [==============================] - 1s 61us/step - loss: 0.0067 - acc: 8.3542e-04\n",
      "Epoch 12/100\n",
      "13167/13167 [==============================] - 1s 73us/step - loss: 0.0052 - acc: 8.3542e-04\n",
      "Epoch 13/100\n",
      "13167/13167 [==============================] - 1s 64us/step - loss: 0.0041 - acc: 8.3542e-04\n",
      "Epoch 14/100\n",
      "13167/13167 [==============================] - 1s 56us/step - loss: 0.0032 - acc: 8.3542e-04\n",
      "Epoch 15/100\n",
      "13167/13167 [==============================] - 1s 60us/step - loss: 0.0026 - acc: 8.3542e-04\n",
      "Epoch 16/100\n",
      "13167/13167 [==============================] - 1s 59us/step - loss: 0.0020 - acc: 8.3542e-04\n",
      "Epoch 17/100\n",
      "13167/13167 [==============================] - 1s 60us/step - loss: 0.0016 - acc: 8.3542e-04\n",
      "Epoch 18/100\n",
      "13167/13167 [==============================] - 1s 59us/step - loss: 0.0013 - acc: 8.3542e-04\n",
      "Epoch 19/100\n",
      "13167/13167 [==============================] - 1s 59us/step - loss: 0.0011 - acc: 8.3542e-04\n",
      "Epoch 20/100\n",
      "13167/13167 [==============================] - 1s 66us/step - loss: 8.6983e-04 - acc: 8.3542e-04\n",
      "Epoch 21/100\n",
      "13167/13167 [==============================] - 1s 64us/step - loss: 7.0607e-04 - acc: 8.3542e-04\n",
      "Epoch 22/100\n",
      "13167/13167 [==============================] - 1s 62us/step - loss: 5.7391e-04 - acc: 8.3542e-04\n",
      "Epoch 23/100\n",
      "13167/13167 [==============================] - 1s 66us/step - loss: 4.6700e-04 - acc: 8.3542e-04\n",
      "Epoch 24/100\n",
      "13167/13167 [==============================] - 1s 65us/step - loss: 3.8034e-04 - acc: 8.3542e-04\n",
      "Epoch 25/100\n",
      "13167/13167 [==============================] - 1s 62us/step - loss: 3.0999e-04 - acc: 8.3542e-04\n",
      "Epoch 26/100\n",
      "13167/13167 [==============================] - 1s 62us/step - loss: 2.5279e-04 - acc: 8.3542e-04\n",
      "Epoch 27/100\n",
      "13167/13167 [==============================] - 1s 64us/step - loss: 2.0624e-04 - acc: 8.3542e-04\n",
      "Epoch 28/100\n",
      "13167/13167 [==============================] - 1s 62us/step - loss: 1.6833e-04 - acc: 8.3542e-04\n",
      "Epoch 29/100\n",
      "13167/13167 [==============================] - 1s 65us/step - loss: 1.3743e-04 - acc: 8.3542e-04\n",
      "Epoch 30/100\n",
      "13167/13167 [==============================] - 1s 66us/step - loss: 1.1222e-04 - acc: 8.3542e-04\n",
      "Epoch 31/100\n",
      "13167/13167 [==============================] - 1s 66us/step - loss: 9.1662e-05 - acc: 8.3542e-04\n",
      "Epoch 32/100\n",
      "13167/13167 [==============================] - 1s 66us/step - loss: 7.4882e-05 - acc: 8.3542e-04\n",
      "Epoch 33/100\n",
      "13167/13167 [==============================] - 1s 89us/step - loss: 6.1177e-05 - acc: 8.3542e-04\n",
      "Epoch 34/100\n",
      "13167/13167 [==============================] - 1s 75us/step - loss: 4.9989e-05 - acc: 8.3542e-04\n",
      "Epoch 35/100\n",
      "13167/13167 [==============================] - 1s 63us/step - loss: 4.0848e-05 - acc: 8.3542e-04\n",
      "Epoch 36/100\n",
      "13167/13167 [==============================] - 1s 68us/step - loss: 3.3383e-05 - acc: 8.3542e-04\n",
      "Epoch 37/100\n",
      "13167/13167 [==============================] - 1s 68us/step - loss: 2.7279e-05 - acc: 8.3542e-04\n",
      "Epoch 38/100\n",
      "13167/13167 [==============================] - 1s 62us/step - loss: 2.2298e-05 - acc: 8.3542e-04\n",
      "Epoch 39/100\n",
      "13167/13167 [==============================] - 1s 52us/step - loss: 1.8225e-05 - acc: 8.3542e-04\n",
      "Epoch 40/100\n",
      "13167/13167 [==============================] - 1s 55us/step - loss: 1.4895e-05 - acc: 8.3542e-04\n",
      "Epoch 41/100\n",
      "13167/13167 [==============================] - 1s 55us/step - loss: 1.2166e-05 - acc: 8.3542e-04\n",
      "Epoch 42/100\n",
      "13167/13167 [==============================] - 1s 55us/step - loss: 9.9541e-06 - acc: 8.3542e-04\n",
      "Epoch 43/100\n",
      "13167/13167 [==============================] - 1s 61us/step - loss: 8.1396e-06 - acc: 8.3542e-04\n",
      "Epoch 44/100\n",
      "13167/13167 [==============================] - 1s 65us/step - loss: 6.6462e-06 - acc: 8.3542e-04\n",
      "Epoch 45/100\n",
      "13167/13167 [==============================] - 1s 66us/step - loss: 5.4369e-06 - acc: 8.3542e-04\n",
      "Epoch 46/100\n",
      "13167/13167 [==============================] - 1s 48us/step - loss: 4.4338e-06 - acc: 8.3542e-04\n",
      "Epoch 47/100\n",
      "13167/13167 [==============================] - 1s 48us/step - loss: 3.6335e-06 - acc: 8.3542e-04\n",
      "Epoch 48/100\n",
      "13167/13167 [==============================] - 1s 51us/step - loss: 2.9807e-06 - acc: 8.3542e-04\n",
      "Epoch 49/100\n",
      "13167/13167 [==============================] - 1s 51us/step - loss: 2.3920e-06 - acc: 8.3542e-04\n",
      "Epoch 50/100\n",
      "13167/13167 [==============================] - 1s 52us/step - loss: 2.0154e-06 - acc: 8.3542e-04\n",
      "Epoch 51/100\n",
      "13167/13167 [==============================] - 1s 52us/step - loss: 1.6453e-06 - acc: 8.3542e-04\n",
      "Epoch 52/100\n",
      "13167/13167 [==============================] - 1s 52us/step - loss: 1.2570e-06 - acc: 8.3542e-04\n",
      "Epoch 53/100\n",
      "13167/13167 [==============================] - 1s 51us/step - loss: 1.0710e-06 - acc: 8.3542e-04\n",
      "Epoch 54/100\n",
      "13167/13167 [==============================] - 1s 52us/step - loss: 9.5367e-07 - acc: 8.3542e-04\n",
      "Epoch 55/100\n",
      "13167/13167 [==============================] - 1s 51us/step - loss: 9.5367e-07 - acc: 8.3542e-04\n",
      "Epoch 56/100\n",
      "13167/13167 [==============================] - 1s 49us/step - loss: 8.5677e-07 - acc: 8.3542e-04\n",
      "Epoch 57/100\n",
      "13167/13167 [==============================] - 1s 58us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 58/100\n",
      "13167/13167 [==============================] - 1s 63us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 59/100\n",
      "13167/13167 [==============================] - 1s 51us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 60/100\n",
      "13167/13167 [==============================] - 1s 57us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 61/100\n",
      "13167/13167 [==============================] - 1s 56us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 62/100\n",
      "13167/13167 [==============================] - 1s 55us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 63/100\n",
      "13167/13167 [==============================] - 1s 50us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 64/100\n",
      "13167/13167 [==============================] - 1s 49us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 65/100\n",
      "13167/13167 [==============================] - 1s 50us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 66/100\n",
      "13167/13167 [==============================] - 1s 51us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 67/100\n",
      "13167/13167 [==============================] - 1s 50us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 68/100\n",
      "13167/13167 [==============================] - 1s 52us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 69/100\n",
      "13167/13167 [==============================] - 1s 50us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 70/100\n",
      "13167/13167 [==============================] - 1s 50us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 71/100\n",
      "13167/13167 [==============================] - 1s 51us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 72/100\n",
      "13167/13167 [==============================] - 1s 51us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 73/100\n",
      "13167/13167 [==============================] - 1s 50us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 74/100\n",
      "13167/13167 [==============================] - 1s 52us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 75/100\n",
      "13167/13167 [==============================] - 1s 52us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 76/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13167/13167 [==============================] - 1s 56us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 77/100\n",
      "13167/13167 [==============================] - 1s 51us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 78/100\n",
      "13167/13167 [==============================] - 1s 49us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 79/100\n",
      "13167/13167 [==============================] - 1s 44us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 80/100\n",
      "13167/13167 [==============================] - 1s 51us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 81/100\n",
      "13167/13167 [==============================] - 1s 57us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 82/100\n",
      "13167/13167 [==============================] - 1s 56us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 83/100\n",
      "13167/13167 [==============================] - 1s 50us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 84/100\n",
      "13167/13167 [==============================] - 1s 49us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 85/100\n",
      "13167/13167 [==============================] - 1s 50us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 86/100\n",
      "13167/13167 [==============================] - 1s 51us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 87/100\n",
      "13167/13167 [==============================] - 1s 51us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 88/100\n",
      "13167/13167 [==============================] - 1s 52us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 89/100\n",
      "13167/13167 [==============================] - 1s 53us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 90/100\n",
      "13167/13167 [==============================] - 1s 51us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 91/100\n",
      "13167/13167 [==============================] - 1s 56us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 92/100\n",
      "13167/13167 [==============================] - 1s 65us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 93/100\n",
      "13167/13167 [==============================] - 1s 51us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 94/100\n",
      "13167/13167 [==============================] - 1s 63us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 95/100\n",
      "13167/13167 [==============================] - 1s 75us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 96/100\n",
      "13167/13167 [==============================] - 1s 58us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 97/100\n",
      "13167/13167 [==============================] - 1s 55us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 98/100\n",
      "13167/13167 [==============================] - 1s 60us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 99/100\n",
      "13167/13167 [==============================] - 1s 68us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 100/100\n",
      "13167/13167 [==============================] - 1s 61us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "3292/3292 [==============================] - 0s 59us/step\n",
      "Epoch 1/100\n",
      "13167/13167 [==============================] - 1s 76us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 2/100\n",
      "13167/13167 [==============================] - 1s 49us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 3/100\n",
      "13167/13167 [==============================] - 1s 53us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 4/100\n",
      "13167/13167 [==============================] - 1s 44us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 5/100\n",
      "13167/13167 [==============================] - 0s 36us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 6/100\n",
      "13167/13167 [==============================] - 0s 34us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 7/100\n",
      "13167/13167 [==============================] - 0s 37us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 8/100\n",
      "13167/13167 [==============================] - 1s 39us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 9/100\n",
      "13167/13167 [==============================] - 1s 38us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 10/100\n",
      "13167/13167 [==============================] - 1s 41us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 11/100\n",
      "13167/13167 [==============================] - 1s 46us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 12/100\n",
      "13167/13167 [==============================] - 1s 41us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 13/100\n",
      "13167/13167 [==============================] - 1s 43us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 14/100\n",
      "13167/13167 [==============================] - 1s 40us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 15/100\n",
      "13167/13167 [==============================] - 1s 43us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 16/100\n",
      "13167/13167 [==============================] - 1s 44us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 17/100\n",
      "13167/13167 [==============================] - 1s 39us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 18/100\n",
      "13167/13167 [==============================] - 1s 39us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 19/100\n",
      "13167/13167 [==============================] - 1s 39us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 20/100\n",
      "13167/13167 [==============================] - 1s 41us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 21/100\n",
      "13167/13167 [==============================] - 1s 46us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 22/100\n",
      "13167/13167 [==============================] - 1s 41us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 23/100\n",
      "13167/13167 [==============================] - 1s 44us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 24/100\n",
      "13167/13167 [==============================] - 1s 43us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 25/100\n",
      "13167/13167 [==============================] - 1s 41us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 26/100\n",
      "13167/13167 [==============================] - 1s 43us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 27/100\n",
      "13167/13167 [==============================] - 0s 38us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 28/100\n",
      "13167/13167 [==============================] - 0s 37us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 29/100\n",
      "13167/13167 [==============================] - 0s 36us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 30/100\n",
      "13167/13167 [==============================] - 1s 40us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 31/100\n",
      "13167/13167 [==============================] - 0s 37us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 32/100\n",
      "13167/13167 [==============================] - 0s 37us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 33/100\n",
      "13167/13167 [==============================] - 0s 38us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 34/100\n",
      "13167/13167 [==============================] - 1s 44us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 35/100\n",
      "13167/13167 [==============================] - 1s 41us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 36/100\n",
      "13167/13167 [==============================] - 1s 38us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 37/100\n",
      "13167/13167 [==============================] - 0s 37us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 38/100\n",
      "13167/13167 [==============================] - 0s 38us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 39/100\n",
      "13167/13167 [==============================] - 1s 41us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 40/100\n",
      "13167/13167 [==============================] - 1s 42us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 41/100\n",
      "13167/13167 [==============================] - 1s 42us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 42/100\n",
      "13167/13167 [==============================] - 1s 43us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 43/100\n",
      "13167/13167 [==============================] - 1s 46us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 44/100\n",
      "13167/13167 [==============================] - 1s 39us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 45/100\n",
      "13167/13167 [==============================] - 1s 42us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 46/100\n",
      "13167/13167 [==============================] - 0s 37us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 47/100\n",
      "13167/13167 [==============================] - 1s 41us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 48/100\n",
      "13167/13167 [==============================] - 1s 40us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 49/100\n",
      "13167/13167 [==============================] - 1s 39us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 50/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13167/13167 [==============================] - 0s 37us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 51/100\n",
      "13167/13167 [==============================] - 1s 38us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 52/100\n",
      "13167/13167 [==============================] - 1s 41us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 53/100\n",
      "13167/13167 [==============================] - 1s 43us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 54/100\n",
      "13167/13167 [==============================] - 1s 41us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 55/100\n",
      "13167/13167 [==============================] - 1s 40us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 56/100\n",
      "13167/13167 [==============================] - 1s 38us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 57/100\n",
      "13167/13167 [==============================] - 1s 41us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 58/100\n",
      "13167/13167 [==============================] - 1s 49us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 59/100\n",
      "13167/13167 [==============================] - 1s 43us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 60/100\n",
      "13167/13167 [==============================] - 1s 43us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 61/100\n",
      "13167/13167 [==============================] - 0s 37us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 62/100\n",
      "13167/13167 [==============================] - 0s 32us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 63/100\n",
      "13167/13167 [==============================] - 1s 40us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 64/100\n",
      "13167/13167 [==============================] - 1s 44us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 65/100\n",
      "13167/13167 [==============================] - 1s 40us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 66/100\n",
      "13167/13167 [==============================] - 0s 38us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 67/100\n",
      "13167/13167 [==============================] - 1s 39us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 68/100\n",
      "13167/13167 [==============================] - 1s 45us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 69/100\n",
      "13167/13167 [==============================] - 1s 43us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 70/100\n",
      "13167/13167 [==============================] - 1s 46us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 71/100\n",
      "13167/13167 [==============================] - 1s 53us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 72/100\n",
      "13167/13167 [==============================] - 1s 43us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 73/100\n",
      "13167/13167 [==============================] - 1s 46us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 74/100\n",
      "13167/13167 [==============================] - 1s 45us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 75/100\n",
      "13167/13167 [==============================] - 0s 38us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 76/100\n",
      "13167/13167 [==============================] - 1s 50us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 77/100\n",
      "13167/13167 [==============================] - 1s 44us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 78/100\n",
      "13167/13167 [==============================] - 1s 54us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 79/100\n",
      "13167/13167 [==============================] - 1s 45us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 80/100\n",
      "13167/13167 [==============================] - 1s 43us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 81/100\n",
      "13167/13167 [==============================] - 1s 41us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 82/100\n",
      "13167/13167 [==============================] - 1s 39us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 83/100\n",
      "13167/13167 [==============================] - 1s 40us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 84/100\n",
      "13167/13167 [==============================] - 1s 40us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 85/100\n",
      "13167/13167 [==============================] - 1s 39us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 86/100\n",
      "13167/13167 [==============================] - 1s 40us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 87/100\n",
      "13167/13167 [==============================] - 1s 44us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 88/100\n",
      "13167/13167 [==============================] - 1s 43us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 89/100\n",
      "13167/13167 [==============================] - 1s 52us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 90/100\n",
      "13167/13167 [==============================] - 1s 47us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 91/100\n",
      "13167/13167 [==============================] - 1s 44us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 92/100\n",
      "13167/13167 [==============================] - 1s 43us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 93/100\n",
      "13167/13167 [==============================] - 1s 41us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 94/100\n",
      "13167/13167 [==============================] - 1s 41us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 95/100\n",
      "13167/13167 [==============================] - 1s 46us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 96/100\n",
      "13167/13167 [==============================] - 1s 42us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 97/100\n",
      "13167/13167 [==============================] - 1s 47us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 98/100\n",
      "13167/13167 [==============================] - 1s 46us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 99/100\n",
      "13167/13167 [==============================] - 0s 36us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 100/100\n",
      "13167/13167 [==============================] - 1s 49us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "3292/3292 [==============================] - 0s 49us/step\n",
      "Epoch 1/100\n",
      "13167/13167 [==============================] - 1s 59us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 2/100\n",
      "13167/13167 [==============================] - 1s 43us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 3/100\n",
      "13167/13167 [==============================] - 1s 41us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 4/100\n",
      "13167/13167 [==============================] - 1s 40us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 5/100\n",
      "13167/13167 [==============================] - 1s 41us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 6/100\n",
      "13167/13167 [==============================] - 1s 41us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 7/100\n",
      "13167/13167 [==============================] - 1s 40us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 8/100\n",
      "13167/13167 [==============================] - 1s 39us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 9/100\n",
      "13167/13167 [==============================] - 1s 41us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 10/100\n",
      "13167/13167 [==============================] - 1s 40us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 11/100\n",
      "13167/13167 [==============================] - ETA: 0s - loss: 8.3446e-07 - acc: 7.5402e-0 - 1s 38us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 12/100\n",
      "13167/13167 [==============================] - 1s 42us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 13/100\n",
      "13167/13167 [==============================] - 1s 39us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 14/100\n",
      "13167/13167 [==============================] - 1s 41us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 15/100\n",
      "13167/13167 [==============================] - 1s 41us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 16/100\n",
      "13167/13167 [==============================] - 1s 40us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 17/100\n",
      "13167/13167 [==============================] - 1s 46us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 18/100\n",
      "13167/13167 [==============================] - 1s 48us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 19/100\n",
      "13167/13167 [==============================] - 1s 42us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 20/100\n",
      "13167/13167 [==============================] - 1s 46us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 21/100\n",
      "13167/13167 [==============================] - 1s 41us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 22/100\n",
      "13167/13167 [==============================] - 1s 41us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 23/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13167/13167 [==============================] - 1s 40us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 24/100\n",
      "13167/13167 [==============================] - 1s 48us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 25/100\n",
      "13167/13167 [==============================] - 1s 45us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 26/100\n",
      "13167/13167 [==============================] - 1s 44us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 27/100\n",
      "13167/13167 [==============================] - 1s 42us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 28/100\n",
      "13167/13167 [==============================] - 1s 41us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 29/100\n",
      "13167/13167 [==============================] - 1s 39us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 30/100\n",
      "13167/13167 [==============================] - 1s 42us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 31/100\n",
      "13167/13167 [==============================] - 1s 38us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 32/100\n",
      "13167/13167 [==============================] - 1s 41us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 33/100\n",
      "13167/13167 [==============================] - 1s 41us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 34/100\n",
      "13167/13167 [==============================] - 1s 39us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 35/100\n",
      "13167/13167 [==============================] - 0s 38us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 36/100\n",
      "13167/13167 [==============================] - 0s 38us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 37/100\n",
      "13167/13167 [==============================] - 1s 39us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 38/100\n",
      "13167/13167 [==============================] - 0s 38us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 39/100\n",
      "13167/13167 [==============================] - 0s 38us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 40/100\n",
      "13167/13167 [==============================] - 1s 39us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 41/100\n",
      "13167/13167 [==============================] - 0s 38us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 42/100\n",
      "13167/13167 [==============================] - 1s 39us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 43/100\n",
      "13167/13167 [==============================] - 1s 39us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 44/100\n",
      "13167/13167 [==============================] - 1s 39us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 45/100\n",
      "13167/13167 [==============================] - 1s 39us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 46/100\n",
      "13167/13167 [==============================] - 1s 40us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 47/100\n",
      "13167/13167 [==============================] - 1s 50us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 48/100\n",
      "13167/13167 [==============================] - 1s 44us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 49/100\n",
      "13167/13167 [==============================] - 1s 40us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 50/100\n",
      "13167/13167 [==============================] - 1s 56us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 51/100\n",
      "13167/13167 [==============================] - 1s 48us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 52/100\n",
      "13167/13167 [==============================] - 1s 47us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 53/100\n",
      "13167/13167 [==============================] - 0s 37us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 54/100\n",
      "13167/13167 [==============================] - 1s 41us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 55/100\n",
      "13167/13167 [==============================] - 1s 53us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 56/100\n",
      "13167/13167 [==============================] - 1s 60us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 57/100\n",
      "13167/13167 [==============================] - 1s 51us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 58/100\n",
      "13167/13167 [==============================] - 1s 46us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 59/100\n",
      "13167/13167 [==============================] - 1s 48us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 60/100\n",
      "13167/13167 [==============================] - 1s 49us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 61/100\n",
      "13167/13167 [==============================] - 1s 51us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 62/100\n",
      "13167/13167 [==============================] - 1s 51us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 63/100\n",
      "13167/13167 [==============================] - 1s 64us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 64/100\n",
      "13167/13167 [==============================] - 1s 54us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 65/100\n",
      "13167/13167 [==============================] - 1s 45us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 66/100\n",
      "13167/13167 [==============================] - 1s 45us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 67/100\n",
      "13167/13167 [==============================] - 1s 45us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 68/100\n",
      "13167/13167 [==============================] - 1s 47us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 69/100\n",
      "13167/13167 [==============================] - 1s 49us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 70/100\n",
      "13167/13167 [==============================] - 1s 53us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 71/100\n",
      "13167/13167 [==============================] - 1s 52us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 72/100\n",
      "13167/13167 [==============================] - 1s 50us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 73/100\n",
      "13167/13167 [==============================] - 1s 48us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 74/100\n",
      "13167/13167 [==============================] - 1s 49us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 75/100\n",
      "13167/13167 [==============================] - 1s 52us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 76/100\n",
      "13167/13167 [==============================] - 1s 50us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 77/100\n",
      "13167/13167 [==============================] - 1s 50us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 78/100\n",
      "13167/13167 [==============================] - 1s 49us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 79/100\n",
      "13167/13167 [==============================] - 1s 63us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 80/100\n",
      "13167/13167 [==============================] - 1s 58us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 81/100\n",
      "13167/13167 [==============================] - 1s 58us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 82/100\n",
      "13167/13167 [==============================] - 1s 52us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 83/100\n",
      "13167/13167 [==============================] - 1s 50us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 84/100\n",
      "13167/13167 [==============================] - 1s 56us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 85/100\n",
      "13167/13167 [==============================] - 1s 54us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 86/100\n",
      "13167/13167 [==============================] - 1s 53us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 87/100\n",
      "13167/13167 [==============================] - 1s 49us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 88/100\n",
      "13167/13167 [==============================] - 1s 50us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 89/100\n",
      "13167/13167 [==============================] - 1s 48us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 90/100\n",
      "13167/13167 [==============================] - 1s 50us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 91/100\n",
      "13167/13167 [==============================] - 1s 49us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 92/100\n",
      "13167/13167 [==============================] - 1s 50us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 93/100\n",
      "13167/13167 [==============================] - 1s 51us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 94/100\n",
      "13167/13167 [==============================] - 1s 48us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 95/100\n",
      "13167/13167 [==============================] - 1s 52us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 96/100\n",
      "13167/13167 [==============================] - 1s 52us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 97/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13167/13167 [==============================] - 1s 53us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 98/100\n",
      "13167/13167 [==============================] - 1s 52us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 99/100\n",
      "13167/13167 [==============================] - 1s 49us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "Epoch 100/100\n",
      "13167/13167 [==============================] - 1s 63us/step - loss: 8.3446e-07 - acc: 8.3542e-04\n",
      "3292/3292 [==============================] - 0s 70us/step\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unknown loss function:hinge_loss",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-da114110cb0c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m         model.compile(optimizer=j, \n\u001b[1;32m     14\u001b[0m               \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m               metrics=['accuracy'])\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mtest_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_dev\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_dev\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/training/checkpointable/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    472\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    473\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 474\u001b[0;31m       \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    475\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mcompile\u001b[0;34m(self, optimizer, loss, metrics, loss_weights, sample_weight_mode, weighted_metrics, target_tensors, distribute, **kwargs)\u001b[0m\n\u001b[1;32m    464\u001b[0m       \u001b[0mloss_functions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m       \u001b[0mloss_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    467\u001b[0m       \u001b[0mloss_functions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mloss_function\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    468\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_functions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_functions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/keras/losses.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(identifier)\u001b[0m\n\u001b[1;32m    190\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midentifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m     \u001b[0midentifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midentifier\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 192\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mdeserialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midentifier\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midentifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdeserialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midentifier\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/keras/losses.py\u001b[0m in \u001b[0;36mdeserialize\u001b[0;34m(name, custom_objects)\u001b[0m\n\u001b[1;32m    181\u001b[0m       \u001b[0mmodule_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mglobals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m       \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m       printable_module_name='loss function')\n\u001b[0m\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mdeserialize_keras_object\u001b[0;34m(identifier, module_objects, custom_objects, printable_module_name)\u001b[0m\n\u001b[1;32m    191\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mfn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m         raise ValueError('Unknown ' + printable_module_name + ':' +\n\u001b[0;32m--> 193\u001b[0;31m                          function_name)\n\u001b[0m\u001b[1;32m    194\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Unknown loss function:hinge_loss"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(76, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(60, activation=tf.nn.softmax),\n",
    "    keras.layers.Dense(40, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(20, activation=tf.nn.softmax),\n",
    "    keras.layers.Dense(10, activation=tf.nn.softmax),\n",
    "    keras.layers.Dense(9, activation=tf.nn.softmax) # for the 8 bins \n",
    "])\n",
    "\n",
    "for i in ['sparse_categorical_crossentropy', 'hinge_loss', 'log_loss','losses.mean_pairwise_squared_error']:\n",
    "    for j in [tf.train.AdamOptimizer(), tf.train.GradientDescentOptimizer(learning_rate=0.1),\n",
    "             tf.train.AdagradOptimizer(learning_rate = 0.1)]:\n",
    "        model.compile(optimizer=j, \n",
    "              loss=i,\n",
    "              metrics=['accuracy'])\n",
    "        model.fit(np.asarray(x_train), np.asarray(y_train), epochs=100)\n",
    "        test_loss, test_acc = model.evaluate(np.asarray(x_dev), y_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(76, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(60, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(40, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(20, activation=tf.nn.sigmoid),\n",
    "    keras.layers.Dense(10, activation=tf.nn.softmax),\n",
    "    keras.layers.Dense(9, activation=tf.nn.softmax) # for the 8 bins \n",
    "])\n",
    "\n",
    "for i in ['sparse_categorical_crossentropy', 'hinge_loss', 'log_loss','losses.mean_pairwise_squared_error']:\n",
    "    for j in [tf.train.AdamOptimizer(), tf.train.GradientDescentOptimizer(learning_rate=0.1),\n",
    "             tf.train.AdagradOptimizer(learning_rate = 0.1)]:\n",
    "        model.compile(optimizer=j, \n",
    "              loss=i,\n",
    "              metrics=['accuracy'])\n",
    "        model.fit(np.asarray(x_tra), y_tra, epochs=50)\n",
    "        test_loss, test_acc = model.evaluate(np.asarray(x_dev), y_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
